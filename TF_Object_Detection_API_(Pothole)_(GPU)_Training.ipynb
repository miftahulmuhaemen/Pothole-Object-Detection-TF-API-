{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF Object Detection API (Pothole) (GPU) - Training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wx_T-hnQok8I",
        "929pMimeVcP8"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miftahulmuhaemen/Pothole-Object-Detection-TF-API-/blob/master/TF_Object_Detection_API_(Pothole)_(GPU)_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx_T-hnQok8I",
        "colab_type": "text"
      },
      "source": [
        "# GPU AVAILABLITY\n",
        "> Finding out the avalability of the GPU Support before training the Model on Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fRHYm29nvZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "# !pip install gputil\n",
        "# !pip install psutil\n",
        "# !pip install humanize\n",
        "# import psutil\n",
        "# import humanize\n",
        "# import os\n",
        "# import GPUtil as GPU\n",
        "# GPUs = GPU.getGPUs()\n",
        "# gpu = GPUs[0]\n",
        "# def printm():\n",
        "#  process = psutil.Process(os.getpid())\n",
        "#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "# printm() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDRuDoDhsele",
        "colab_type": "text"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xunUmazMuAoz",
        "colab_type": "text"
      },
      "source": [
        "Getting authentication from GCP and GDRIVE.\n",
        "> GCP for its Storage and Ai-Platform (Default-Disabled)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhXJA71i9RR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !gcloud auth login\n",
        "# !gcloud auth application-default login"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSR4f7B7LNni",
        "colab_type": "text"
      },
      "source": [
        "> Gdrive for local drive, sometimes some command only accept local, which is impossible for gs:// path, then again Google Colab has limited time use (12 hours) and everything would be erased after that, so to maintain more easier uses we mount it and use it as 'eternal local drive'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRDDxq50LUMW",
        "colab_type": "code",
        "outputId": "14bdd653-002e-4694-b74a-510559558020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe-9nKWFuhvs",
        "colab_type": "text"
      },
      "source": [
        "Installing necessary library to run and copying Tensorflow Object Detection API from its repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXK5HNtgCgto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!apt-get install -y -qq protobuf-compiler python-pil python-lxml\n",
        "!pip install tensorboardcolab absl-py\n",
        "!git clone --quiet https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ7m0rTlu3ZI",
        "colab_type": "text"
      },
      "source": [
        "Adding path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WocgY8mC_kd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "os.chdir('models/research')\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "sys.path.append('/content/models/research/slim')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32ZOj1v_vIRG",
        "colab_type": "text"
      },
      "source": [
        "Test the system if it is ready to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRNkIphkDKSZ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgI2kzPdvP8v",
        "colab_type": "text"
      },
      "source": [
        "Extracting the necessary library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC68pHr94sFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!chmod u+rwx object_detection/dataset_tools/create_pycocotools_package.sh \n",
        "!object_detection/dataset_tools/create_pycocotools_package.sh /tmp/pycocotools\n",
        "!python setup.py sdist\n",
        "!(cd slim && python setup.py sdist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_AY76YDvZBQ",
        "colab_type": "text"
      },
      "source": [
        "Adding the project name for using the Google Storage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIZrWAZbE6YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%capture\n",
        "# !gcloud config set project robust-app-devs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPW_ExKIwDi4",
        "colab_type": "text"
      },
      "source": [
        "# PREPARE DATASET\n",
        "\n",
        "Put the training and evaluation dataset to each directory in Google Storage/Google Drive, and Tensorflow Object Detection API only accept TFRecord (.tfrecord/.record).\n",
        "\n",
        "Then download and configure the pipeline config each model dataset path or the checkpoint path as well.\n",
        "\n",
        "*   Total data : 1793 tfrecords (Frames) [16 Files]\n",
        "*   Image Augmentation (On-Fly) : Random Horizontal Flip, Crop, Saturation, Hue, Contrast, Brightness and Grayscale.\n",
        "*   Image Resizer : 480x480 (Squeezed) ~ 228\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgBSOPNBhjF1",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "bucket_name = 'tf_cnn_pothole_drone_4803018/data' #@param {type:\"string\"}\n",
        "fps = '15FPS' #@param [\"1FPS\",\"15FPS\",\"30FPS\"]\n",
        "ratio = '6040' #@param [\"9010\",\"8020\",\"6040\"]\n",
        "# augmentation = '_FALSEAUGMENTATION' #@param [\"_FALSEAUGMENTATION\",\"\"]\n",
        "PretrainedModel = 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03' #@param [\"ssd_mobilenet_v1_coco_2018_01_28\", \"ssd_mobilenet_v2_coco_2018_03_29\", \"ssd_mobilenet_v3_large_coco_2019_08_14\",\"ssd_mobilenet_v3_small_coco_2019_08_14\", \"ssd_inception_v2_coco_2018_01_28\", \"ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFFPzcqxvpDp",
        "colab_type": "text"
      },
      "source": [
        "# TRAINING ON GCP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B37q9wcwYUh",
        "colab_type": "text"
      },
      "source": [
        "If only you want to train it on Ai-Platform, or you could test your training on local (Colab) first, then if it lack the power you want, switch it to this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvHn4c757yAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !gcloud ai-platform  jobs submit training {PretrainedModel}_{fps}_{ratio} \\\n",
        "# --runtime-version 1.12 --job-dir=gs://tf_cnn_pothole_drone_4803018/ModelTraining/model/{PretrainedModel}_{fps}_{ratio} \\\n",
        "# --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz,/content/drive/'My Drive'/pycocotools-2.0.tar.gz \\\n",
        "# --module-name object_detection.model_main \\\n",
        "# --region us-central1 \\\n",
        "# --config /content/drive/'My Drive'/cloud.yml \\\n",
        "# -- \\\n",
        "# --model_dir=gs://tf_cnn_pothole_drone_4803018/ModelTraining/model/{PretrainedModel}_{fps}_{ratio} \\\n",
        "# --pipeline_config_path=gs://tf_cnn_pothole_drone_4803018/ModelTraining/config/data_{PretrainedModel}_pipeline_{fps}_{ratio}.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UVysI3A3GOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !gcloud ai-platform jobs stream-logs object_detection_training_08112019_colab_v3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2RwwwjNvjyA",
        "colab_type": "text"
      },
      "source": [
        "# TRAINING ON GOOGLE COLABORATORY (LOCAL)\n",
        "\n",
        "   Failed, due to various reason, mainly Out of Memory(OOM) and NaN Loss. OOM triggered because this Colab using P4/K80/P100 (1x), so the solution could be the GCP, utilizing more RAM packed with its GPU, but\n",
        "   this solution is costly. It's even more worthless if the result is NaN Loss where the solution is to increasing the batch number or reducing learning rate, where lead us to OOM again, hell loop. Here is the failed list,\n",
        "    # data_ssd_mobilenet_v2_coco_2018_03_29_pipeline.config \\\n",
        "    # data_ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03_pipeline.config \\\n",
        "    # data_faster_rcnn_resnet101_coco_2018_01_28_pipeline.config \\\n",
        "    # data_faster_rcnn_resnet50_coco_2018_01_28_pipeline.config \\\n",
        "    # data_rfcn_resnet101_coco_2018_01_28_pipeline.config \\\n",
        "    # data_faster_rcnn_inception_v2_coco_2018_01_28_pipeline.config \\\n",
        "\n",
        "   Worked one,\n",
        "    # data_ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03_pipeline.config \\\n",
        "    # data_ssd_inception_v2_coco_2018_01_28_pipeline.config \\\n",
        "    # data_ssd_mobilenet_v1_coco_2018_01_28_pipeline.config \\\n",
        "    # data_ssd_mobilenet_v2_coco_2018_03_29_pipeline.config \\\n",
        "    # data_ssd_mobilenet_v3_large_coco_2019_08_14_pipeline.config \\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f5OxFEmLq8i",
        "colab_type": "text"
      },
      "source": [
        "> Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv7J7_X3sys9",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "!python object_detection/model_main.py \\\n",
        "    --pipeline_config_path=/content/drive/'My Drive'/ModelTraining/config/data_{PretrainedModel}_pipeline_{fps}_{ratio}.config \\\n",
        "    --model_dir=/content/drive/'My Drive'/ModelTraining/model/{PretrainedModel}_{fps}_{ratio} \\\n",
        "    --alsologtostderr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED-pebYuLuW3",
        "colab_type": "text"
      },
      "source": [
        "> Google Cloud Storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esrxr3lE4ZJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python object_detection/model_main.py \\\n",
        "#     --pipeline_config_path=gs://{bucket_name}/data_{PretrainedModel}_pipeline_{fps}_{ratio}.config\\\n",
        "#     --model_dir=gs://{bucket_name}/model/{PretrainedModel}_{fps}_{ratio} \\\n",
        "#     --alsologtostderr    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06ShQGNExu69",
        "colab_type": "text"
      },
      "source": [
        "# WATCH THE PROGRESS ON TENSORBOARD\n",
        "\n",
        "model_output refer to model_dir/job_dir where the output model is saved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK2D3_DRL4l5",
        "colab_type": "text"
      },
      "source": [
        "> Google Cloud Tensorboard (Cloud Shell)\n",
        "\n",
        "tensorboard --logdir=gs://model_output --port=8080"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rgh-5eSOMBG-",
        "colab_type": "text"
      },
      "source": [
        "> Collaboratory Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLzaqFbcHwHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "from tensorboard import notebook\n",
        "%tensorboard --logdir /content/drive/'My Drive'/ModelTraining/model/{PretrainedModel}_{fps}_{ratio}/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsiSrJk1vdtl",
        "colab_type": "text"
      },
      "source": [
        "# EXPORTING CHECKPOINT \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGpFCUOOvs9B",
        "colab_type": "text"
      },
      "source": [
        "In order to test it on real data, we need to export the checkpoint first.\n",
        "\n",
        "Check the checkpoint number, model.ckpt--{number_checkpoint},\n",
        "> Google Cloud Storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rujJjJeQ5dyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !gsutil ls gs://{bucket_name}/model/{PretrainedModel}_{fps}_{ratio}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJPoDX56MhGm",
        "colab_type": "text"
      },
      "source": [
        "> Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASDSp9qM5-r2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /content/drive/'My Drive'/ModelTraining/model/{PretrainedModel}_{fps}_{ratio}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QscchlIeoPvV",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "Checkpoint = 30000 #@param {type:\"number\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQcliL61SjtK",
        "colab_type": "text"
      },
      "source": [
        "Now export it,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irlDmQtaMqnN",
        "colab_type": "text"
      },
      "source": [
        "> Google Cloud Storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ksoL6-y7C1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python object_detection/export_inference_graph.py \\\n",
        "# --input_type image_tensor \\\n",
        "# --trained_checkpoint_prefix gs://{bucket_name}/model/{PretrainedModel}_{fps}_{ratio}/model.ckpt-{Checkpoint} \\\n",
        "# --pipeline_config_path gs://{bucket_name}/data_{PretrainedModel}_{fps}_{ratio}_pipeline.config \\\n",
        "# --output_directory gs://{bucket_name}/export/{PretrainedModel}_{fps}_{ratio}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhEBHKpsMsW1",
        "colab_type": "text"
      },
      "source": [
        "> Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJptgvNE6iAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python object_detection/export_inference_graph.py \\\n",
        "# --input_type=image_tensor \\\n",
        "# --trained_checkpoint_prefix=/content/drive/'My Drive'/ModelTraining/model/{PretrainedModel}_{fps}_{ratio}/model.ckpt-{Checkpoint} \\\n",
        "# --pipeline_config_path=/content/drive/'My Drive'/ModelTraining/config/data_{PretrainedModel}_pipeline_{fps}_{ratio}.config \\\n",
        "# --output_directory=/content/drive/'My Drive'/ModelTraining/export/{PretrainedModel}_{fps}_{ratio}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEzcre4XHETX",
        "colab_type": "text"
      },
      "source": [
        "# TEST AGAINST REAL DATA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LV75ql3UtkIr",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from moviepy.editor import VideoFileClip\n",
        "from IPython.display import HTML\n",
        "%matplotlib inline\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils  import label_map_util\n",
        "from object_detection.utils  import visualization_utils as vis_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CjBZk8BcTcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_image(image):\n",
        "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
        "    # you should return the final output (image with lines are drawn on lanes)\n",
        "    with detection_graph.as_default():\n",
        "        with tf.Session(graph=detection_graph) as sess:\n",
        "            image_process = detect_objects(image, sess, detection_graph)\n",
        "            return image_process"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYyiqg7Ccf0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_objects(image_np, sess, detection_graph):\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "    # Each box represents a part of the image where a particular object was detected.\n",
        "    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "\n",
        "    # Each score represent how level of confidence for each of the objects.\n",
        "    # Score is shown on the result image, together with the class label.\n",
        "    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "\n",
        "    # Actual detection.\n",
        "    (boxes, scores, classes, num_detections) = sess.run(\n",
        "        [boxes, scores, classes, num_detections],\n",
        "        feed_dict={image_tensor: image_np_expanded})\n",
        "\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        np.squeeze(boxes),\n",
        "        np.squeeze(classes).astype(np.int32),\n",
        "        np.squeeze(scores),\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    return image_np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs2HLuSRUyGj",
        "colab_type": "text"
      },
      "source": [
        "Video feed path still hardcoded, so you need to define it yourself.\n",
        "And acces the output from Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpmifD0JzQf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = [\"DJI_0033\",\"DJI_0035\", \"DJI_0043\",\"DJI_0046\"]\n",
        "models = [\"ssd_mobilenet_v2_coco_2018_03_29\",\"ssd_mobilenet_v3_large_coco_2019_08_14\",\"ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03\"]\n",
        "frames = [\"30FPS\",\"15FPS\",\"1FPS\"]\n",
        "splits = [\"9010\",\"8020\",\"6040\"]\n",
        "\n",
        "for video_name in test:\n",
        "  for model in models :\n",
        "    for frame in frames :\n",
        "      for split in splits :\n",
        "\n",
        "        # Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "        # Adding path to the exported model and its label, also the class number.\n",
        "        PATH_TO_CKPT = '/content/drive/My Drive/ModelTraining/export/'+model+'_'+frame+'_'+split+'/frozen_inference_graph.pb'\n",
        "        PATH_TO_LABELS = os.path.join('/content/drive/My Drive/ExportedModel', 'tf_label_map.pbtxt')\n",
        "        NUM_CLASSES = 1\n",
        "\n",
        "        # Parsing Model\n",
        "        detection_graph = tf.Graph()\n",
        "        with detection_graph.as_default():\n",
        "            od_graph_def = tf.GraphDef()\n",
        "            with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "                serialized_graph = fid.read()\n",
        "                od_graph_def.ParseFromString(serialized_graph)\n",
        "                tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "        # Parsing Label\n",
        "        label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "        categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "        category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "        clip1 = VideoFileClip(\"/content/drive/My Drive/RAW_FOOTAGE_BJB_POTHOLE/\"+video_name+\".MOV\")\n",
        "        white_output = \"/content/drive/My Drive/ExportedModel/exported_videos/LastCheckpoint/\"+model+\"_\"+frame+\"_\"+split+\"_\"+video_name+\".mp4\" #Make sure it's the same path as the line below.\n",
        "        exist = !find /content/drive/'My Drive'/ExportedModel/exported_videos/LastCheckpoint/{model}_{frame}_{split}_{video_name}.mp4  -type f | wc -l #To prevent overwriting the same file\n",
        "        if exist == ['1'] :\n",
        "          pass\n",
        "        else :\n",
        "          white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
        "          white_clip.write_videofile(white_output, audio=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "929pMimeVcP8",
        "colab_type": "text"
      },
      "source": [
        "# SOURCE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNvkL4enxBbh",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "> https://averdones.github.io/tensorflow-object-detection-star-wars/\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "> https://github.com/averdones/star_wars_object_detection/blob/master/object_detection_sw.ipynb\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "> https://cloud.google.com/blog/products/gcp/training-an-object-detector-using-cloud-machine-learning-engine\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "> https://github.com/tensorflow/models/tree/master/research/object_detection"
      ]
    }
  ]
}